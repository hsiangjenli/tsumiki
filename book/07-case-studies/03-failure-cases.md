# 7.3 失敗案例與對策

## 概要

AITDD 的導入過程中，我們遭遇多種失敗情境。本章整理實際案例與對應手法，協助你避免同樣的陷阱，並將經驗轉化成團隊的標準作業。

## 主要失敗類型

### 1. 過度依賴 AI

#### 案例：放棄決策權

**情境**
- 開發者完全接受 AI 的設計與實作建議
- 專案特有需求逐漸被忽略
- 團隊缺少討論與創意發揮

**問題**
- 商業邏輯過度一般化，無法回應實際需求
- 採用千篇一律的架構，欠缺差異化
- 技術討論減少，個人技能停滯

**影響**
- 設計品質下降
- 創造力受限
- 學習與成長機會減少
- 團隊合作力下滑

#### 對策：刻意限制 AI 介入範圍

1. **明確決策流程**
```
人類決定方向 → AI 協助實作 → 審查結果 → 最終判斷仍由人做出
```

2. **保護創造力**
- 設計階段必須由人提出多個方案
- 將 AI 視為參考，而非唯一答案
- 關鍵創意與差異化功能由人親自處理

3. **維持技能熟練度**
- 定期安排手動實作與程式練習
- 在程式碼審查時說明設計理由
- 技術研究與比較由人主導

### 2. 想定外的程式生成

#### 案例：失控的自動修改

**情境**
- 明明只要求新增一個功能，AI 卻大量修改既有程式
- 變更範圍超出預期，導致整體行為被破壞

**常見問題**
- 無關檔案也被改動
- AI 自行添加額外功能
- 與原先架構方針不符
- 產生難以追蹤的副作用

**實例**
```
指示：新增使用者註冊功能
預期：新增 registration.js
實際：auth.js、user.js、database.js 也被大幅修改，認證系統整體遭到破壞
```

#### 對策：事前設定與分段執行

1. **執行前確認清單**
```
□ 清楚列出可修改檔案
□ 說明期望的實作模式
□ 明示不可動到的區域
□ 明確界定範圍與邊界
```

2. **分段小步實作**
- 不一次要求大型變更
- 以檔案或功能為單位拆分
- 每段完成後先檢查再進下一步

3. **徹底檢視差異**
```
1. 確認被修改的檔案清單
2. 逐檔檢視修改內容
3. 偵測想定外變更並回滾
4. 確認無誤後才進行下一步
```

### 3. 品質管理成本暴增

#### 案例：審查疲勞

**情境**
- 審查 AI 程式碼的時間比預期多出許多
- 專案整體時間雖然縮短，審查者卻疲憊不堪

**問題**
- 不得不檢查大量自動生成的程式碼
- 需確認 AI 推測是否合理
- 品質檢查標準不明確
- 長時間審查導致集中力下降

**數據比較**
```
傳統開發：
- 實作 1–2 天
- 審查 30–60 分鐘

AITDD：
- 實作 1 小時內
- 審查 1 小時以上
- 審查次數增加 10–20 倍
```

#### 對策：品質管理制度化

1. **建立標準審查清單**
```
品質檢查重點：
1. 測試結果是否全綠
2. 是否存在重大安全弱點
3. 是否有顯著效能退化
4. 重構目標是否達標
5. 程式碼品質是否符合要求
```

2. **導入推測可視化**
- 使用信號燈標註：
  - 🟢 確定內容 → 輕度檢查
  - 🟡 推測內容 → 加強檢查
  - 🔴 未知內容 → 深入檢查

3. **分散審查負荷**
```
審查策略：
- 依重要度排序
- 自動化可檢查的項目
- 把人力集中在需要判斷的部分
- 以階段性審查避免一次看完所有內容
```

### 4. 測試策略失敗

#### 案例：測試設計過於薄弱

**情境**
- AI 產生的測試案例不完整，未覆蓋關鍵情境
- 缺乏整合測試，導致系統層級錯誤

**教訓**
- 測試案例需要人工審閱調整
- 須補足邊界情境與異常流程
- 必須建立整合／E2E 測試策略

#### 對策
- 在 TDD 流程中強制執行測試審查
- 依需求文件比對測試覆蓋情況
- 對關鍵功能建立綜合測試與驗證

## 總結建議

- 主動定義 AI 的角色與限制，避免被動接受結果
- 在每次實作前先設定範圍、預期檔案與不可動區域
- 建立標準化的審查流程與可視化工具
- 將測試策略視為需求的一部分，持續審查與補強

只要持續檢討並調整流程，這些失敗都能轉化為成熟的作業制度，讓 AITDD 在團隊內穩健落地。
